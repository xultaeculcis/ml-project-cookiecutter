{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#ml-project-cookiecutter","title":"ml-project-cookiecutter","text":"<p>A cookiecutter template for my private ML projects.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>During my career I worked in a lot of different ML projects - computer vision, NLP, classical ML, time series forecasting and others. The projects ranged from pure R&amp;D, through PoCs and production ready stuff. Whenever I would start a new project, I found myself copying things from a bunch of different sources and my old projects again and again - recreating and duplicating the work I did a dozen times before. Cookiecutter project templates to the resque!</p> <p>The usage of technologies and certain patterns in the template is highly opinionated and is dictated by years of experience of working with Data Scientists and R&amp;D Engineers. As an ML Engineer, I would often find myself working with low-quality code, written by others in notebooks or scripts, without any form of documentation, standardized coding style or even a way to reproduce the environment or analysis results. Moving that to production? Good luck!</p> <p>In my opinion, the fastest way to move ML stuff to production is to force the Data Scientists to write quality code from the start. Want to add your changes to the repo? Sure, once all <code>pre-commit</code> hooks are green you'll be able to commit your changes. Add to that a CI pipeline, automated tests and PR review process, and you'll have an easier way to ensure that the code and models are production ready faster.</p> <p>Won't that slow down Data Scientists? Yes. At first at least. They'll have to learn working with a set of standard python tools that are known in the industry for years. Spending a few hours on this is way better than spending a few weeks on productionizing the code later. Your ML/MLOps Engineers will thank you for this.</p> Note <p>Now, standardized code style, type hints and good documentation are just a small step to success. All of this doesn't mean much without code understanding and following good coding practices. In my opinion every great Data Scientist or ML Engineer should also be a great programmer. Learn how to write clean, testable code. Learn data structures, algorithms and design patterns. Have a CI in place. Verify changes via PRs and automated tests. Automate as much as you can. Integrate with other services that will allow you to ensure reproducibility, scaling, experiment tracing, artifact versioning and easier deployment.</p> <p>This project was greatly inspired by Cookiecutter Data Science project.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Integrated <code>pre-commit</code> hooks:<ul> <li><code>pyupgrade</code></li> <li><code>codespell</code></li> <li><code>docformatter</code></li> <li><code>ruff</code></li> <li><code>mypy</code></li> <li><code>pytest</code></li> <li>And a few more...</li> </ul> </li> <li>Project documentation creation using MkDocs with     Material theme.</li> <li>CI pipelines (Azure DevOps)</li> <li>Some useful utility classes and functions I found myself re-implementing again and again</li> <li>Folder structure inspired by Cookiecutter Data Science</li> <li><code>uv.lock</code> file for reproducibility</li> <li>Makefile with a bunch of pre-defined commands</li> <li>Secrets support using <code>.env</code> files and pydantic-settings</li> <li><code>pyproject.toml</code> with project tool configs</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":"<p>To get started, please check out this guide.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Please refer to this guide.</p>"},{"location":"#running-tests","title":"Running tests","text":"<p>To run the unit tests, execute:</p> <pre><code>make test\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Project structure and tool usage is highly opinionated within this project. As the times change, so do the best practices. I will try to keep the project up to date with the latest tools and practices.</p> <p>The goal of this project is to make it easier to start, structure, reproduce, maintain and later deploy an ML project. The stuff in it is based on my own experiences and might not suit your needs. If you think something should be done differently, feel free to create an issue or fork the repo for your own usage. It's an MIT license, so you can do whatever the hell you want with it.</p> <p>Creating pull requests and filing issues is welcome. I'd love to hear what works for you and what does not. Although I cannot promise to not close them if I disagree with you.</p>"},{"location":"guide/","title":"Getting started","text":""},{"location":"guide/#getting-started","title":"Getting started","text":""},{"location":"guide/#requirements","title":"Requirements","text":"<ul> <li>Read: Cookiecutter Data Science Docs for a general overview</li> <li>Python 3.12+</li> <li>uv</li> <li>Cookiecutter Python package &gt;= 2.1.1</li> </ul>"},{"location":"guide/#creating-a-new-project","title":"Creating a new project","text":"<p>Run:</p> <pre><code>cookiecutter https://github.com/xultaeculcis/ml-project-cookiecutter\n</code></pre> <p>You will be prompted to provide project info one argument at a time:</p> <pre><code>project_name (project_name): My ML project\nrepo_name (my-ml-project):\npackage_name (my_ml_project):\nauthor_name (Your name (or your organization/company/team)): xultaeculcsis\nrepo_url (https://github.com/xultaeculcsis/my-ml-project):\nproject_description (A short description of the project): Just an ML project :)\nSelect python_version\n1 - 3.11\n2 - 3.12\n3 - 3.13\nChoose from [1/2/3] (1): 1\nsanitized_python_version (311):\nSelect license:\n1 - MIT\n2 - Apache 2.0\n3 - BSD-3-Clause\n4 - Beerware\n5 - GLWTS\n6 - Proprietary\n7 - Empty license file\nChoose from [1/2/3/4/5/6/7] (1): 1\n</code></pre> <p>The <code>repo_name</code>, <code>package_name</code>, <code>repo_url</code> and <code>sanitized_python_version</code> will be automatically standardized and provided for you. You can change them to your liking, though.</p>"},{"location":"guide/#working-with-the-project","title":"Working with the project","text":""},{"location":"guide/#project-directory-structure","title":"Project directory structure","text":"<p>The resulting project structure will look like this:</p> <pre><code>my-ml-project/\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 analysis                          &lt;- EDA artifacts.\n\u2502   \u251c\u2500\u2500 auxiliary                         &lt;- The auxiliary, third party data.\n\u2502   \u251c\u2500\u2500 inference                         &lt;- Inference results from your models.\n\u2502   \u251c\u2500\u2500 interim                           &lt;- Intermediate data that has been transformed.\n\u2502   \u251c\u2500\u2500 processed                         &lt;- The final, canonical data sets for modeling.\n\u2502   \u2514\u2500\u2500 raw                               &lt;- The original, immutable data dump.\n\u251c\u2500\u2500 Dockerfile                            &lt;- Dockerfile definition.\n\u251c\u2500\u2500 docs                                  &lt;- The mkdocs documentation sources.\n\u2502   \u251c\u2500\u2500 api_ref                           &lt;- Source package docs.\n\u2502   \u2502   \u251c\u2500\u2500 consts.md\n\u2502   \u2502   \u251c\u2500\u2500 core\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 configs.md\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 settings.md\n\u2502   \u2502   \u2514\u2500\u2500 utils.md\n\u2502   \u251c\u2500\u2500 guides                            &lt;- How-to guides.\n\u2502   \u2502   \u251c\u2500\u2500 contributing.md\n\u2502   \u2502   \u251c\u2500\u2500 makefile-usage.md\n\u2502   \u2502   \u251c\u2500\u2500 setup-dev-env.md\n\u2502   \u2502   \u2514\u2500\u2500 tests.md\n\u2502   \u251c\u2500\u2500 index.md                          &lt;- Docs homepage.\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 env-dev.yaml                          &lt;- Conda environment definition with development dependencies.\n\u251c\u2500\u2500 env.yaml                              &lt;- Main Conda environment definition with only the necessary packages.\n\u251c\u2500\u2500 LICENSE                               &lt;- The license file.\n\u251c\u2500\u2500 Makefile                              &lt;- Makefile with commands like `make docs` or\n\u2502                                            `make pc`.\n\u251c\u2500\u2500 mkdocs.yml\n\u251c\u2500\u2500 src\n\u2502   \u2514\u2500\u2500 my_ml_project                     &lt;- Project source code.\n\u2502       \u2502                                    This will be different depending on your input during project creation.\n\u2502       \u251c\u2500\u2500 consts                        &lt;- Constants to be used across the project.\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 directories.py\n\u2502       \u2502   \u251c\u2500\u2500 logging.py\n\u2502       \u2502   \u2514\u2500\u2500 reproducibility.py\n\u2502       \u251c\u2500\u2500 core                           &lt;- Core project stuff. E.g., the base classes\n\u2502       \u2502   \u2502                                for step entrypoint configs.\n\u2502       \u2502   \u251c\u2500\u2500 configs\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 __init__.py\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 argument_parsing.py\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 base.py\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u2514\u2500\u2500 settings.py\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 py.typed\n\u2502       \u2514\u2500\u2500 utils                         &lt;- Utility functions and classes.\n\u2502           \u251c\u2500\u2500 __init__.py\n\u2502           \u251c\u2500\u2500 gpu.py\n\u2502           \u251c\u2500\u2500 logging.py\n\u2502           \u251c\u2500\u2500 mlflow.py\n\u2502           \u2514\u2500\u2500 serialization.py\n\u251c\u2500\u2500 notebooks                             &lt;- Jupyter notebooks. Naming convention is a\n\u2502                                            number (for ordering), the creator's initials,\n\u2502                                            and a short `-` delimited description, e.g.\n\u2502                                            `1.0-jqp-initial-data-exploration`.\n\u251c\u2500\u2500 pyproject.toml                        &lt;- Contains build system requirements\n\u2502                                            and information, which are used by pip to build\n\u2502                                            the package and project tooling configs.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 setup.py\n\u2514\u2500\u2500 tests                                 &lt;- The tests directory.\n    \u251c\u2500\u2500 conftest.py                       &lt;- Contains test fixtures and utility functions.\n    \u251c\u2500\u2500 e2e                               &lt;- Contains end-to-end tests.\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 integration                       &lt;- Contains integration tests.\n    \u2514\u2500\u2500 unit                              &lt;- Contains unit tests.\n</code></pre> <p>Most of those folders were described in detail in the Cookiecutter Data Science Docs.</p>"},{"location":"guide/#environment-setup","title":"Environment setup","text":"<p>The post-generation hook will initialize <code>git</code> repo for you. It will also set up <code>main</code> to track the remote branch. An initial commit will be created with all repo files added to it. You can modify them and amend the commit at your convenience.</p>"},{"location":"guide/#via-makefile","title":"Via Makefile","text":"<p>Right after creating a new project from the cookiecutter template, you'll need to freeze the dependencies. Initial <code>pyproject.toml</code> has a minimal set of dependencies needed for the helper functions, test execution and docs creation. Note that most of the dependencies are not pinned in the <code>pyproject.toml</code>. This is done on purpose to ensure that new projects can be created with the most up-to-date packages. Once you create the lock file, you can pin specific versions.</p> <p>To lock the environment, run:</p> <pre><code>make env\n</code></pre> <p>This command will set up the environment for you. It will also install <code>pre-commit</code> hooks and the project in an editable mode.</p>"},{"location":"guide/#manually","title":"Manually","text":"<p>If you are not on Linux the setup via <code>Makefile</code> might not work. In that case run the following commands manually.</p> <p>To set up your local env from scratch, run:</p> <ol> <li> <p>Create <code>uv.lock</code> file:</p> <pre><code>uv sync --all-groups\n</code></pre> </li> <li> <p>Install <code>pre-commit</code> hooks:</p> <pre><code>uv run pre-commit install\n</code></pre> </li> </ol> Note <p>Once you've initialized git repo, created the lock file(s) and pinned the package versions, you should commit the changes and push them to a remote repository as an <code>Initial commit</code>.</p>"},{"location":"guide/#pre-commit-hooks","title":"Pre-commit hooks","text":"<p>This project uses <code>pre-commit</code> package for managing and maintaining <code>pre-commit</code> hooks.</p> <p>To ensure code quality - please make sure that you have it configured.</p> <ol> <li> <p>Install <code>pre-commit</code> and following packages: <code>ruff</code>, <code>mypy</code>, <code>pytest</code>.</p> </li> <li> <p>Install <code>pre-commit</code> hooks by running: <code>uv run pre-commit install</code></p> </li> <li> <p>The command above will automatically run formatters, code checks and other steps defined     in the<code>.pre-commit-config.yaml</code></p> </li> <li> <p>All of those checks will also be run whenever a new commit is being created i.e. when you run <code>git commit -m \"blah\"</code></p> </li> <li> <p>You can also run it manually with this command: <code>uv run pre-commit run --all-files</code> or with <code>make pc</code></p> </li> </ol> <p>You can manually disable <code>pre-commit</code> hooks by running: pre-commit uninstall Use this only in exceptional cases.</p>"},{"location":"guide/#environment-variables","title":"Environment variables","text":"<p>Ask your colleagues for <code>.env</code> files which aren't included in this repository and put them inside the repo's root directory. Please, never put secrets in the source control. Always align with your IT department security practices.</p> <p>To see what variables you need see the <code>.env-sample</code> file.</p>"},{"location":"guide/#ci-pipelines","title":"CI pipelines","text":"<p>Currently, the project supports only Azure DevOps Pipelines.</p> <p>By default, the project comes with a single CI pipeline that runs a set of simplified pre-commit hooks on each PR commit that targets the <code>main</code> branch.</p>"},{"location":"guide/#documentation","title":"Documentation","text":"<p>We use MkDocs with Material theme.</p> <p>To build the docs, run:</p> <pre><code>make docs\n</code></pre> <p>If you want to verify the docs locally, use:</p> <pre><code>uv run mkdocs serve\n</code></pre> <p>A page like the one below should be available to you under: http://127.0.0.1:8000/</p> <p></p> Note <p>Please note that google style docstrings are used throughout the repo.</p>"},{"location":"license/","title":"License","text":""},{"location":"license/#license","title":"License","text":""},{"location":"license/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2023 xultaeculcis</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"}]}